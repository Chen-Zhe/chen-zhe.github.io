<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 大白鲸笔记本</title>
    <link>https://chen-zhe.github.io/blog/post/</link>
    <description>Recent content in Posts on 大白鲸笔记本</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://chen-zhe.github.io/blog/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS User Notes for Deep Learning</title>
      <link>https://chen-zhe.github.io/blog/p/aws-user-notes-for-deep-learning/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/p/aws-user-notes-for-deep-learning/</guid>
      <description>Updates 2022-01-04: To quote AWS support, &amp;ldquo;Over the last few months, we have seen a rapid increase in customer demand for our high-performance GPU instances. Several AWS teams are still working around the clock to provision additional capacity for our customers and remediate this situation.&amp;rdquo; Currently it has been very difficult to launch g4dn.xlarge spot instances without getting spot capacity error. I advise wait until night at East Coast to try again and launch g4dn.</description>
    </item>
    
    <item>
      <title>How to get hired as a software engineer? A note to myself after 3 interviews as an interviewer</title>
      <link>https://chen-zhe.github.io/blog/p/how-to-get-hired-as-a-software-engineer-a-note-to-myself-after-3-interviews-as-an-interviewer/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/p/how-to-get-hired-as-a-software-engineer-a-note-to-myself-after-3-interviews-as-an-interviewer/</guid>
      <description>TL;DR
To pose myself as a good software engineer candidate, I need to:
 Demonstrate passion to learn Provide more utility to the job position as a senior engineer Keep my resume short and relevant Tailor my resume for each position that I apply to Be mentally prepared for a project with relevancy to the position I&amp;rsquo;m applying to Not forget about the basics of computing (data structure and algorithms) Demonstrate Passion for coding  Background In the past few weeks, I participated in 3 interview sessions to hire more software engineers for developing the Spark ETL pipeline (using Scala) of a product.</description>
    </item>
    
    <item>
      <title>Manuscript: Cell Sector Clustering</title>
      <link>https://chen-zhe.github.io/blog/p/manuscript-cell-sector-clustering/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/p/manuscript-cell-sector-clustering/</guid>
      <description>Presentation video at IEEE WCNC 2020
When I was with DataSpark, I was part of a product team building a telco-specific solution that optimizes a telco operator&amp;rsquo;s spending on cell site upgrades to maximize return on investment (ROI). Requested by one of our clients, I designed, implemented and deployed this algorithm to identify cell sector clusters that share user load. Discovery of the sharing capability reduces the need to upgrade cell sites and hence saves upgrade cost.</description>
    </item>
    
    <item>
      <title>Basic usage of GraphX for clique detection</title>
      <link>https://chen-zhe.github.io/blog/p/basic-usage-of-graphx-for-clique-detection/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/p/basic-usage-of-graphx-for-clique-detection/</guid>
      <description>GraphX is a powerful component in Spark that allows graph-based programming and manipulation at very large scale. The only drawback is that it run on RDD and not DataFrame as I&amp;rsquo;m used to in Spark 2.2. Although a Spark package called GraphFrames is available to extend GraphX&amp;rsquo;s power to DataFrame, I recon it&amp;rsquo;s still easier to learn to construct a graph using GraphX and RDD than importing the package in Spark.</description>
    </item>
    
    <item>
      <title>Apache Spark - Save Time with Less Join Operations</title>
      <link>https://chen-zhe.github.io/blog/p/apache-spark-save-time-with-less-join-operations/</link>
      <pubDate>Fri, 28 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/p/apache-spark-save-time-with-less-join-operations/</guid>
      <description>Not long ago, I was tasked to improve our Spark application&amp;rsquo;s runtime performance as some modules takes 7 hours or more to complete on datasets that are not considered very large. This is my conclusion and afterthoughts after countless hours staring at our codebase and YARN application tracking UI. I was able to achieve 30% ~ 80% reduction of runtime, depending on how well the module was written and the nature of operations.</description>
    </item>
    
  </channel>
</rss>
