<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chen Zhe&#39;s Blog</title>
    <link>https://chen-zhe.github.io/blog/</link>
    <description>Recent content on Chen Zhe&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 05 Oct 2019 12:05:00 +0800</lastBuildDate>
    
	<atom:link href="https://chen-zhe.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Manuscript: Cell Sector Clustering</title>
      <link>https://chen-zhe.github.io/blog/2019/10/manuscript-cell-sector-clustering/</link>
      <pubDate>Sat, 05 Oct 2019 12:05:00 +0800</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/2019/10/manuscript-cell-sector-clustering/</guid>
      <description>When I was with DataSpark, I was part of a product team building a telco-specific solution that optimizes a telco operator&amp;rsquo;s spending on cell site upgrades to maximize return on investment (ROI). Requested by one of our clients, I designed, implemented and deployed this algorithm to identify cell sector clusters that share user load. Discovery of the sharing capability reduces the need to upgrade cell sites and hence saves upgrade cost.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://chen-zhe.github.io/blog/page/whoami/</link>
      <pubDate>Sun, 23 Dec 2018 21:46:26 +0800</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/page/whoami/</guid>
      <description>Hi there. I&amp;rsquo;m Chen Zhe.</description>
    </item>
    
    <item>
      <title>Notes on GraphX and Clique Detection</title>
      <link>https://chen-zhe.github.io/blog/2018/12/notes-on-graphx-and-clique-detection/</link>
      <pubDate>Sat, 15 Dec 2018 21:05:12 +0800</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/2018/12/notes-on-graphx-and-clique-detection/</guid>
      <description>GraphX is a powerful component in Spark that allows graph-based programming and manipulation at very large scale. The only drawback is that it run on RDD and not DataFrame as I&amp;rsquo;m used to in Spark 2.2. Although a Spark package called GraphFrames is currently available to extend GraphX&amp;rsquo;s power to DataFrame, I recon it&amp;rsquo;s still easier to learn to construct a graph using GraphX and RDD than importing the package in Spark, especially when the Spark cluster is not managed by me.</description>
    </item>
    
    <item>
      <title>Apache Spark - Save Time with Less Join Operations</title>
      <link>https://chen-zhe.github.io/blog/2018/09/apache-spark-save-time-with-less-join-operations/</link>
      <pubDate>Fri, 28 Sep 2018 21:05:12 +0800</pubDate>
      
      <guid>https://chen-zhe.github.io/blog/2018/09/apache-spark-save-time-with-less-join-operations/</guid>
      <description>Not long ago, I was tasked to improve our Spark application&amp;rsquo;s runtime performance as some modules takes 7 hours or more to complete on datasets that are not considered very large. This is my conclusion and afterthoughts after countless hours staring at our codebase and YARN application tracking UI. I was able to achieve 30% ~ 80% reduction of runtime, depending on how well the module was written and the nature of operations.</description>
    </item>
    
  </channel>
</rss>